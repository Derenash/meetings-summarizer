You see, it depends, right? Because this means that the on-chain contracts need to be represented syntactically in some sort of canonical form that corresponds to the semantics, right? So there needs to be that kind of relationship there to establish the equivalence of different sort of one or two different, right? That's what you want from a normal form is that two equivalent statements, when you normalize them, you want them to be syntactically the same. I don't know what that current situation is or if that applies to the interaction that model that you're using, right? That's the thing that I would want to look at while exploring the feasibility of proof of proving, I think. Yeah. So you can express the same computation in different interaction nets, but we now have the equality checking, which is, I'm not sure exactly what the current upper bound on the time complexity of that is, but it's definitely, I think they have done some improvements recently. But like in terms of, I think you have to walk all the possible paths in one of two that you're comparing and it's like proportional to that, the time complexity, but it's still... So that's one thing that makes it a little less trivial, right? Because now we have a syntactic representation, right? We have two different possible syntactic representations of the same computation, right? So if we were using, for example, just propositional logic or something, we could convert it to a normal form where any two equivalent statements have the same structure, but it's not the case with interaction nets. So you have to do something dynamic in order to establish equivalence, which actually, I mean, in some ways, that gives the sort of pattern matching even more of an advantage over, say, if we go back to OpenAI case, they would have to... It makes their job harder, but it makes efficient search through a large database of patterns more advantageous because you can have multiple equivalent patterns. But I do think it would be ideal still, of course, to have a single canonical form for each, such that anything that's equivalent when it actually hits the chain will have the same representation, the same exact representation, right? Because then if two things are different syntactically, you know for a fact they have different meanings in that case, whereas you don't in what you just said, right? Yeah. And maybe it would make sense to have a simpler syntax for expressing those constraints that might also be compilable to interaction nets, but might have a more canonical normal form. Mm-hmm. Yeah. So that definitely adds a layer to the research and development of it. But I think that if we can demonstrate that it works for... Say we demonstrate it works for some simpler model, that's a good step towards a proof of concept. Yeah. And we don't necessarily have to express those constraints in interaction nets because if the validators run the proof search or the validation of those proofs using interaction nets, or even if the actual constraints are not expressed in interaction nets, it's still like what we want. It's still parallelizing the actual main computational work that's being done. That's true. And what's interesting... Oh, sorry. Go ahead. Sorry. Okay. Fine. So what I was thinking is imagine we have the ability to publish interaction nets to chain and we have the ability to publish this canonical form of constraints. So the thing is you could actually publish your own algorithms to help other people search for it. And then you're more likely to have your contract and your transactions verified quicker. If you're publishing, hey, use this algorithm. It'll really help you perform that search or something. And this type of thing is actually not fully original, this sort of publishing so-called hints. For example, zero knowledge, things like Starkware,